syntax = "proto3";

package proto;

//service definition STT
service STT {
    rpc streamSpeechToText (stream RecognizeRequest) returns (stream RecognizeResponse);
}

message TextResponse {
    string message = 1;
}

message AzureOptions {
    message FromSubscription {
        string subscription_key = 1;
        string region = 2;
    }
    oneof speech_config {
        FromSubscription from_subscription = 1;
        string from_url = 2;
    }
}

message SttServiceOptions {
    oneof options {
        AzureOptions azure_options = 1;
    }
}

message RecognizeRequest {
    RecognitionConfig config = 1;
    RecognitionAudio audio = 2;
    string uuid = 3;
    SttServiceOptions stt_service_options = 4;
}

    // Provides information to the recognizer that specifies how to process the request
message RecognitionConfig {
    enum AudioEncoding {
        ENCODING_UNSPECIFIED = 0;
        LINEAR16 = 1;
        FLAC = 2;
        // MULAW = 3;
        // AMR = 4;
        // AMR_WB = 5;
        // OGG_OPUS = 6;
        // SPEEX_WITH_HEADER_BYTE = 7;
    }
    
    AudioEncoding encoding = 1;
    int32 sample_rate_hertz = 2; // Valid values are: 8000-48000.
    string language_code = 3;
    int32 max_alternatives = 4;
    bool punctuation = 5;
    repeated SpeechContext speech_contexts = 6;
    int32 audio_channel_count = 7;
    // RecognitionMetadata metadata = 9;
    string model = 10;
    bool raw = 11;
    int32 data_bytes = 12;
    bool word_level = 13;
    string callsid = 14;
    repeated string boostPhrase = 15;
    string stt_engine = 16;
    string ms_endpoint = 17;
    enum RecognitionType {
        CONTINUOUS = 0;
        ONCE = 1;
    }
    RecognitionType recognize_type = 18;
    int32 initial_silence_timeout = 19;
    int32 final_silence_timeout = 20;
    repeated string detect_languages = 21; 
}
    
// Either `content` or `uri` must be supplied.
message RecognitionAudio {
    oneof audio_source {
        bytes content = 1;
        string uri = 2;
    }
}
    
message Word {
    float start_time = 1;
    float end_time = 2;
    string word = 3;
    float confidence = 4;
}

message SpeechContext {
    repeated string phrases = 1;
    string type = 2;
}

message RecognizeResponse {
    // Sequential list of transcription results corresponding to
    // sequential portions of audio.
    string RecognitionStatus = 1;
    string Detected_Language = 2;
    repeated SpeechRecognitionResult results = 3;
}
  
message SpeechRecognitionResult {
    repeated SpeechRecognitionAlternative alternatives = 1;
    int32 channel_tag = 2;
    int64 Offset = 3;
    int64 Duration = 4;
}

message SpeechRecognitionAlternative {
    // Transcript text representing the words that the user spoke.
    string Transcript = 1;
    float Confidence = 2;
}
  